{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets used here are taken from [this](https://github.com/Nilabhra/kolkata_nlp_workshop_2019) repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/train.csv')\n",
    "validation = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/valid.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9131, 3), (1142, 3), (1141, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ordered a biryani, and the taste of the Biry...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A nice place to hangout since it has both the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This place is awesome for having lunch or dinn...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got shell of egg in the egg roll. as a resul...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Their biryani is oily, with a bit disconcertin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  I ordered a biryani, and the taste of the Biry...  positive\n",
       "1  A nice place to hangout since it has both the ...  positive\n",
       "2  This place is awesome for having lunch or dinn...  positive\n",
       "3  I got shell of egg in the egg roll. as a resul...  negative\n",
       "4  Their biryani is oily, with a bit disconcertin...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food was excellent with surplus quantity. ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place nearer to the Gitanjali metro stati...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ordered for Aloo tikki with choley just now @0...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hatari is one of those restaurants that our fa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disappointing.......\\nThey have altered the ta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  The food was excellent with surplus quantity. ...  positive\n",
       "1  This place nearer to the Gitanjali metro stati...  positive\n",
       "2  Ordered for Aloo tikki with choley just now @0...  negative\n",
       "3  Hatari is one of those restaurants that our fa...  positive\n",
       "4  Disappointing.......\\nThey have altered the ta...  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This place is amazing. I think the best place ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place has been on my list for quite some ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What a wonderful cold winter evening it was. M...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BabBQ had always been a personal favorite when...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Know for its Deep Dish Pizza this place is sur...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  This place is amazing. I think the best place ...  positive\n",
       "1  This place has been on my list for quite some ...  positive\n",
       "2  What a wonderful cold winter evening it was. M...  positive\n",
       "3  BabBQ had always been a personal favorite when...  positive\n",
       "4  Know for its Deep Dish Pizza this place is sur...  negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I ordered a biryani, and the taste of the Biryani was beyond my expectations and the quantity was also enough comparatively to the price!\\nReally nice much appreciable'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing digits for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "\n",
    "def remove_digits(s):\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    res = s.translate(remove_digits)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(remove_digits)\n",
    "validation['text'] = validation['text'].apply(remove_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=None, lowercase=True,\n",
    "                             ngram_range=(1, 1), min_df=2, binary=True)\n",
    "\n",
    "train_features = vectorizer.fit_transform(train['text'])\n",
    "train_labels = train['class']\n",
    "\n",
    "valid_features = vectorizer.transform(validation['text'])\n",
    "valid_labels = validation['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "valid_labels = le.transform(valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Dropout(rate=0.2, input_shape=train_features.shape[1:]))\n",
    "for _ in range(2):\n",
    "        model.add(Dense(units=64, activation='relu'))\n",
    "        model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an EarlyStopping callback\n",
    "es_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are ready to train the model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9131 samples, validate on 1142 samples\n",
      "WARNING:tensorflow:From /miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "9131/9131 [==============================] - 2s 214us/sample - loss: 0.6426 - acc: 0.6267 - val_loss: 0.5817 - val_acc: 0.6471\n",
      "Epoch 2/15\n",
      "9131/9131 [==============================] - 2s 177us/sample - loss: 0.5433 - acc: 0.6884 - val_loss: 0.4887 - val_acc: 0.7907\n",
      "Epoch 3/15\n",
      "9131/9131 [==============================] - 2s 178us/sample - loss: 0.4450 - acc: 0.8112 - val_loss: 0.4183 - val_acc: 0.8240\n",
      "Epoch 4/15\n",
      "9131/9131 [==============================] - 2s 208us/sample - loss: 0.3724 - acc: 0.8431 - val_loss: 0.4045 - val_acc: 0.8205\n",
      "Epoch 5/15\n",
      "9131/9131 [==============================] - 2s 195us/sample - loss: 0.3157 - acc: 0.8723 - val_loss: 0.4085 - val_acc: 0.8275\n",
      "Epoch 6/15\n",
      "9131/9131 [==============================] - 2s 165us/sample - loss: 0.2845 - acc: 0.8803 - val_loss: 0.4265 - val_acc: 0.8231\n",
      "Epoch 7/15\n",
      "9131/9131 [==============================] - 2s 176us/sample - loss: 0.2505 - acc: 0.8965 - val_loss: 0.4397 - val_acc: 0.8205\n",
      "Epoch 8/15\n",
      "9131/9131 [==============================] - 2s 171us/sample - loss: 0.2200 - acc: 0.9137 - val_loss: 0.4567 - val_acc: 0.8214\n",
      "Epoch 9/15\n",
      "9131/9131 [==============================] - 1s 161us/sample - loss: 0.1937 - acc: 0.9232 - val_loss: 0.4811 - val_acc: 0.8082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x125cbefd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features,\n",
    "                    train_labels,\n",
    "                    epochs=15,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(valid_features, valid_labels),\n",
    "                    callbacks=[es_cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].apply(remove_digits)\n",
    "test_features = vectorizer.transform(test['text'])\n",
    "test_labels = le.transform(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 0s 135us/sample - loss: 0.5658 - acc: 0.7914\n",
      "Accuracy: 79.14%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_features, test_labels)\n",
    "print(\"Accuracy: {0:.2f}%\".format(results[1]*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the training and validation sets and retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, validation), axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=None, lowercase=True,\n",
    "                             ngram_range=(1, 1), min_df=2)\n",
    "\n",
    "features = vectorizer.fit_transform(data['text'])\n",
    "labels = le.fit_transform(data['class'])\n",
    "\n",
    "test_features = vectorizer.transform(test['text'])\n",
    "test_labels = le.transform(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Dropout(rate=0.2, input_shape=features.shape[1:]))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10273 samples, validate on 1141 samples\n",
      "Epoch 1/15\n",
      "10273/10273 [==============================] - 2s 215us/sample - loss: 0.6408 - acc: 0.6189 - val_loss: 0.5679 - val_acc: 0.6670\n",
      "Epoch 2/15\n",
      "10273/10273 [==============================] - 2s 201us/sample - loss: 0.5159 - acc: 0.7512 - val_loss: 0.4445 - val_acc: 0.8168\n",
      "Epoch 3/15\n",
      "10273/10273 [==============================] - 2s 201us/sample - loss: 0.4118 - acc: 0.8279 - val_loss: 0.4257 - val_acc: 0.8195\n",
      "Epoch 4/15\n",
      "10273/10273 [==============================] - 2s 211us/sample - loss: 0.3570 - acc: 0.8544 - val_loss: 0.4232 - val_acc: 0.8317\n",
      "Epoch 5/15\n",
      "10273/10273 [==============================] - 2s 220us/sample - loss: 0.3127 - acc: 0.8749 - val_loss: 0.4362 - val_acc: 0.8265\n",
      "Epoch 6/15\n",
      "10273/10273 [==============================] - 2s 175us/sample - loss: 0.2766 - acc: 0.8925 - val_loss: 0.4824 - val_acc: 0.8177\n",
      "Epoch 7/15\n",
      "10273/10273 [==============================] - 2s 173us/sample - loss: 0.2463 - acc: 0.9021 - val_loss: 0.4892 - val_acc: 0.7967\n",
      "Epoch 8/15\n",
      "10273/10273 [==============================] - 2s 182us/sample - loss: 0.2185 - acc: 0.9158 - val_loss: 0.5392 - val_acc: 0.8037\n",
      "Epoch 9/15\n",
      "10273/10273 [==============================] - 2s 180us/sample - loss: 0.1976 - acc: 0.9212 - val_loss: 0.5570 - val_acc: 0.8011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12a96f518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features,\n",
    "                    labels,\n",
    "                    epochs=15,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(test_features, test_labels),\n",
    "                    callbacks=[es_cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will use this model for serving. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating `sklearn` pipeline for deployment\n",
    "\n",
    "For this we will have to wrap the `tf-keras` model into a `scikit-learn` compatible model class. Then we can use that as a part of a `scikit-learn` pipeline. Let's start by defining a `create_model()` method which would be required for the _scikit-learn model wrapping_ part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(Dropout(rate=0.2, input_shape=(9270,)))\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Same epoch and same batch size\n",
    "model = KerasClassifier(build_fn=create_model, epochs=15, batch_size=512, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('feature_transformer', vectorizer),\n",
    "                  ('classifier', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_transformer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('classifier', <keras.wrappers.scikit_learn.KerasClassifier object at 0x127bfa278>)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "pipeline.fit(data['text'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pipeline to make inferences\n",
    "le.inverse_transform(pipeline.predict([remove_digits('I had a very bad experience you know.')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/sklearn_pipeline.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ready to serialize/pickle the model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Courtesy: https://bit.ly/2IwQKSS\n",
    "# Save the Keras model first\n",
    "pipeline.named_steps['classifier'].model.save('model/keras_model.h5')\n",
    "\n",
    "# This hack allows us to save the sklearn pipeline\n",
    "pipeline.named_steps['classifier'].model = None\n",
    "\n",
    "# Finally, save the pipeline\n",
    "joblib.dump(pipeline, 'model/sklearn_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pipeline first\n",
    "pipeline = joblib.load('model/sklearn_pipeline.pkl')\n",
    "\n",
    "# Then, load the Keras model\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        pipeline.named_steps['classifier'].model = load_model('model/keras_model.h5')\n",
    "\n",
    "# Start making inference\n",
    "le.inverse_transform(pipeline.predict([remove_digits('I had a very bad experience you know.')]))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
